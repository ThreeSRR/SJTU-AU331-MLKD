{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iris_dataset = pd.read_table('iris.data', delimiter=',',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((Iris_dataset.shape[0], 4))\n",
    "labels = np.zeros((Iris_dataset.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for i,category in enumerate(Iris_dataset[4].unique()):\n",
    "    dic[category] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(Iris_dataset.shape[0]):\n",
    "    samples[row][0] = Iris_dataset.iloc[row][0]\n",
    "    samples[row][1] = Iris_dataset.iloc[row][1]\n",
    "    samples[row][2] = Iris_dataset.iloc[row][2]\n",
    "    samples[row][3] = Iris_dataset.iloc[row][3]\n",
    "                               \n",
    "    labels[row][0] = dic[Iris_dataset.iloc[row][4]]\n",
    "    \n",
    "labels = np.reshape(labels, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One vs Rest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ovr(samples, labels):\n",
    "    for label in set(labels):\n",
    "        ones = np.ones_like(labels)\n",
    "        zeros = np.zeros_like(labels)\n",
    "        new_labels = np.where(labels==label, ones, zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearDiscriminantAnalysis(object):\n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        \n",
    "    def train(self, training_samples, training_labels):\n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = training_samples.shape[0]\n",
    "        if sample_dim != training_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "            \n",
    "        positive = training_samples[training_labels==1]\n",
    "        negative = training_samples[training_labels==0]\n",
    "        \n",
    "        # 计算均值\n",
    "        u0 = negative.mean(0)\n",
    "        u1 = positive.mean(0)\n",
    "        \n",
    "        # 计算协方差\n",
    "        tmp0 = np.zeros_like(negative[0] - u0).dot((negative[0] - u0).T)\n",
    "        for row in negative:\n",
    "            tmp0 += (row - u0).dot((row - u0).T)\n",
    "        sigma0 = 1 / (negative.shape[1] - 1) * tmp0\n",
    "        \n",
    "        tmp1 = np.zeros_like(positive[0] - u1).dot((positive[0] - u1).T)\n",
    "        for row in positive:\n",
    "            tmp1 += (row - u1).dot((row - u1).T)\n",
    "        sigma1 = 1 / (positive.shape[1] - 1) * tmp1\n",
    "        \n",
    "        # 类内离散度矩阵\n",
    "        Sw = sigma0 + sigma1\n",
    "        \n",
    "        if isinstance(Sw, np.float64): \n",
    "            w = (1 / Sw) * (u0 - u1)\n",
    "        else:\n",
    "            w = np.linalg.inv(Sw).dot(u0 - u1)\n",
    "            \n",
    "        negative_center = (w.T).dot(u0)\n",
    "        positive_center = (w.T).dot(u1)\n",
    "        \n",
    "        self.w = w\n",
    "        self.negative_center = negative_center\n",
    "        self.positive_center = positive_center\n",
    "        \n",
    "    \n",
    "    def test(self, testing_samples, testing_labels=None):\n",
    "        \n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = testing_samples.shape[0]\n",
    "        if sample_dim != testing_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "            \n",
    "        w = self.w\n",
    "        negative_center = self.negative_center\n",
    "        positive_center = self.positive_center\n",
    "        \n",
    "        predicted_labels = np.zeros((sample_num))\n",
    "        \n",
    "        for i in range(sample_num):\n",
    "            xi = testing_samples[i]\n",
    "            \n",
    "            if abs((w.T).dot(xi) - positive_center) > abs((w.T).dot(xi) - negative_center):\n",
    "                predicted_labels[i] = 0\n",
    "            else:\n",
    "                predicted_labels[i] = 1\n",
    "        \n",
    "        if testing_labels is not None:\n",
    "            acc = accuracy_score(testing_labels, predicted_labels)\n",
    "                \n",
    "        return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDAclassifier(training_samples, training_labels, testing_samples, testing_labels):\n",
    "    \n",
    "    sample_dim = len(training_samples[0])\n",
    "    \n",
    "    LDA = LinearDiscriminantAnalysis(sample_dim)\n",
    "    LDA.train(training_samples, training_labels)\n",
    "    pred = LDA.test(testing_samples, testing_labels)\n",
    "    \n",
    "    test_num = len(testing_labels)\n",
    "    correct_num = 0\n",
    "    for i in range(test_num):\n",
    "        if pred[i] == testing_labels[i]:\n",
    "            correct_num += 1\n",
    "\n",
    "    return [test_num, correct_num, correct_num / test_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(samples, labels, multiclass=False, k=5):\n",
    "    \n",
    "    batch_size = int(samples.shape[0] / k)\n",
    "    correct_classification = 0\n",
    "    total = 0\n",
    "    \n",
    "    if multiclass:\n",
    "        for label in set(labels):\n",
    "            print('one vs rest for label_%d: ' % (label))\n",
    "            ones = np.ones_like(labels)\n",
    "            zeros = np.zeros_like(labels)\n",
    "            new_labels = np.where(labels==label, ones, zeros)\n",
    "\n",
    "            for i in range(0, k):\n",
    "                k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "                k_train_labels = np.hstack([new_labels[0 : i * batch_size], new_labels[(i + 1) * batch_size:]])\n",
    "\n",
    "                k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "                k_val_labels = new_labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "                res = LDAclassifier(k_train_samples, k_train_labels, k_val_samples, k_val_labels)\n",
    "        \n",
    "                correct_classification += res[1]\n",
    "                total += res[0]\n",
    "                print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "                \n",
    "    else:\n",
    "        for i in range(0, k):\n",
    "            k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "            k_train_labels = np.hstack([labels[0 : i * batch_size], labels[(i + 1) * batch_size:]])\n",
    "\n",
    "            k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "            k_val_labels = labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "            res = LDAlassifier(k_train_samples, k_train_labels, k_val_samples, k_val_labels, flag)\n",
    "        \n",
    "            correct_classification += res[1]\n",
    "            total += res[0]\n",
    "            print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "                    \n",
    "    return correct_classification / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = list(range(samples.shape[0]))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "samples = samples[idx]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one vs rest for label_0: \n",
      "ACC of 0th validation : 0.967\n",
      "ACC of 1th validation : 1.000\n",
      "ACC of 2th validation : 0.967\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 1.000\n",
      "one vs rest for label_1: \n",
      "ACC of 0th validation : 0.500\n",
      "ACC of 1th validation : 0.667\n",
      "ACC of 2th validation : 0.667\n",
      "ACC of 3th validation : 0.600\n",
      "ACC of 4th validation : 0.667\n",
      "one vs rest for label_2: \n",
      "ACC of 0th validation : 0.833\n",
      "ACC of 1th validation : 0.700\n",
      "ACC of 2th validation : 0.900\n",
      "ACC of 3th validation : 0.767\n",
      "ACC of 4th validation : 0.933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8111111111111111"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_validation(samples, labels, multiclass=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(object):\n",
    "    \n",
    "    \n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "        self.threshold = 0.5\n",
    "    \n",
    "    \n",
    "    def train(self, training_samples, training_labels):\n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = training_samples.shape[0]\n",
    "        if sample_dim != training_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "            \n",
    "            \n",
    "        w = np.ones_like(training_samples[0])\n",
    "        b = 1\n",
    "        prev_w = w\n",
    "        prev_b = b\n",
    "        \n",
    "        lr = 0.001\n",
    "        iteration = 10000\n",
    "        cnt = 0\n",
    "\n",
    "        while cnt < iteration:\n",
    "            prev_w = w\n",
    "            prev_b = b\n",
    "            w = w - lr * self.derivative_over_w(training_labels, training_samples, w, b)\n",
    "            b = b - lr * self.derivative_over_b(training_labels, training_samples, w, b)\n",
    "            if abs(sum(prev_w-w))<1e-3:\n",
    "                break\n",
    "            cnt += 1\n",
    "            \n",
    "        self.w = w\n",
    "        self.b = b\n",
    "            \n",
    "            \n",
    "    def test(self, testing_samples, testing_labels=None):\n",
    "        sample_dim = self.sample_dim\n",
    "        threshold = self.threshold\n",
    "        \n",
    "        sample_num = testing_samples.shape[0]\n",
    "        if sample_dim != testing_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "            \n",
    "        predicted_labels = np.zeros((sample_num))\n",
    "            \n",
    "        w = self.w\n",
    "        b = self.b\n",
    "        \n",
    "        for i in range(sample_num):\n",
    "            xi = testing_samples[i]\n",
    "            \n",
    "            out = self.sigmoid(xi, b, w)\n",
    "            predicted_labels[i] = 1 if out > threshold else 0\n",
    "            \n",
    "        if testing_labels is not None:\n",
    "            acc = accuracy_score(testing_labels, predicted_labels)\n",
    "            \n",
    "        return predicted_labels\n",
    "    \n",
    "    \n",
    "    def sigmoid(self, x, b, w):\n",
    "        return 1 / (1 + np.exp(- (w.T).dot(x) - b))\n",
    "    \n",
    "    \n",
    "    def prob_positive(self, w, x, b):\n",
    "        tmp = np.exp((w.T).dot(x) + b)\n",
    "        return tmp / (1 + tmp)\n",
    "    \n",
    "    \n",
    "    def derivative_over_w(self, y, x, w, b):\n",
    "        D = np.zeros_like(x[0])\n",
    "        for i in range(x.shape[0]):\n",
    "            D += (x[i] * y[i] - x[i] * self.prob_positive(w, x[i], b))\n",
    "        return -D\n",
    "    \n",
    "    \n",
    "    def derivative_over_b(self, y, x, w, b):\n",
    "        D = 0\n",
    "        for i in range(x.shape[0]):\n",
    "            D += (y[i] - self.prob_positive(w, x[i], b))\n",
    "        return -D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LRclassifier(training_samples, training_labels, testing_samples, testing_labels):\n",
    "    \n",
    "    sample_dim = len(training_samples[0])\n",
    "    \n",
    "    LR = LogisticRegression(sample_dim)\n",
    "    LR.train(training_samples, training_labels)\n",
    "    pred = LR.test(testing_samples, testing_labels)\n",
    "    \n",
    "    test_num = len(testing_labels)\n",
    "    correct_num = 0\n",
    "    for i in range(test_num):\n",
    "        if pred[i] == testing_labels[i]:\n",
    "            correct_num += 1\n",
    "            \n",
    "#     print(confusion_matrix(testing_labels, pred))\n",
    "\n",
    "    return [test_num, correct_num, correct_num / test_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(samples, labels, multiclass=False, k=5):\n",
    "    \n",
    "    batch_size = int(samples.shape[0] / k)\n",
    "    correct_classification = 0\n",
    "    total = 0\n",
    "    \n",
    "    if multiclass:\n",
    "        for label in set(labels):\n",
    "            print('one vs rest for label_%d: ' % (label))\n",
    "            ones = np.ones_like(labels)\n",
    "            zeros = np.zeros_like(labels)\n",
    "            new_labels = np.where(labels==label, ones, zeros)\n",
    "\n",
    "            for i in range(0, k):\n",
    "                k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "                k_train_labels = np.hstack([new_labels[0 : i * batch_size], new_labels[(i + 1) * batch_size:]])\n",
    "\n",
    "                k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "                k_val_labels = new_labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "                res = LRclassifier(k_train_samples, k_train_labels, k_val_samples, k_val_labels)\n",
    "        \n",
    "                correct_classification += res[1]\n",
    "                total += res[0]\n",
    "                print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "                \n",
    "    else:\n",
    "        for i in range(0, k):\n",
    "            k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "            k_train_labels = np.hstack([labels[0 : i * batch_size], labels[(i + 1) * batch_size:]])\n",
    "\n",
    "            k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "            k_val_labels = labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "            res = LRclassifier(k_train_samples, k_train_labels, k_val_samples, k_val_labels, flag)\n",
    "        \n",
    "            correct_classification += res[1]\n",
    "            total += res[0]\n",
    "            print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "                    \n",
    "    return correct_classification / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one vs rest for label_0: \n",
      "ACC of 0th validation : 1.000\n",
      "ACC of 1th validation : 1.000\n",
      "ACC of 2th validation : 1.000\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 1.000\n",
      "one vs rest for label_1: \n",
      "ACC of 0th validation : 0.800\n",
      "ACC of 1th validation : 0.567\n",
      "ACC of 2th validation : 0.633\n",
      "ACC of 3th validation : 0.600\n",
      "ACC of 4th validation : 0.700\n",
      "one vs rest for label_2: \n",
      "ACC of 0th validation : 1.000\n",
      "ACC of 1th validation : 0.900\n",
      "ACC of 2th validation : 0.933\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 0.967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8733333333333333"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_validation(samples, labels, multiclass=True, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NaiveBayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    \n",
    "    def __init__(self, sample_dim):\n",
    "        self.sample_dim = sample_dim\n",
    "    \n",
    "    \n",
    "    def train(self, training_samples, training_labels):\n",
    "        sample_dim = self.sample_dim\n",
    "        sample_num = training_samples.shape[0]\n",
    "        num_class = len(set(training_labels))\n",
    "        \n",
    "        if sample_dim != training_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "        \n",
    "        mean_list = np.zeros((sample_dim, num_class))\n",
    "        std_list = np.zeros((sample_dim, num_class))\n",
    "        class_prior = np.zeros((num_class))\n",
    "        \n",
    "        for i in range(num_class):\n",
    "            class_prior[i] = training_samples[training_labels==i].shape[0] / sample_num\n",
    "        \n",
    "        for dim in range(sample_dim):\n",
    "            for i in range(num_class):\n",
    "                mean_list[dim, i] = np.mean(training_samples[training_labels==i, dim])\n",
    "                std_list[dim, i] = np.std(training_samples[training_labels==i, dim])\n",
    "            \n",
    "        self.class_prior = class_prior\n",
    "        self.mean_list = mean_list\n",
    "        self.std_list = std_list\n",
    "        self.num_class = num_class\n",
    "        \n",
    "    \n",
    "    def test(self, testing_samples, testing_labels=None):\n",
    "        \n",
    "        sample_dim = self.sample_dim\n",
    "        num_class = self.num_class\n",
    "        sample_num = testing_samples.shape[0]\n",
    "        if sample_dim != testing_samples.shape[1]:\n",
    "            raise Exception(\"Input samples are not compatible with this classifier!\")\n",
    "            \n",
    "        predicted_labels = np.zeros((sample_num))\n",
    "        \n",
    "        class_prior = self.class_prior\n",
    "        mean_list = self.mean_list\n",
    "        std_list = self.std_list\n",
    "\n",
    "        \n",
    "        for i in range(sample_num):\n",
    "            xi = testing_samples[i]\n",
    "            \n",
    "            xi_posterior_prob = [1] * num_class\n",
    "            \n",
    "            for idx in range(num_class):\n",
    "                for dim in range(sample_dim):\n",
    "                    xi_prob = self.Gaussian(xi[dim], mean_list[dim, idx], std_list[dim, idx])\n",
    "                    xi_posterior_prob[idx] *= xi_prob\n",
    "            \n",
    "            for idx in range(num_class):\n",
    "                xi_posterior_prob[idx] *= class_prior[idx]\n",
    "            \n",
    "            predicted_labels[i] = np.argmax(np.array(xi_posterior_prob))\n",
    "                \n",
    "        if testing_labels is not None:\n",
    "            acc = accuracy_score(testing_labels, predicted_labels)\n",
    "                \n",
    "        return predicted_labels\n",
    "\n",
    "    def Gaussian(self, x, mean, std):\n",
    "        return np.exp(- 1 / 2 * np.dot((x - mean).T, (x - mean)) / std) / (2 * np.pi * np.sqrt(np.abs(std)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBClassifier(training_samples, training_labels, testing_samples, testing_labels):\n",
    "    \n",
    "    sample_dim = len(training_samples[0])\n",
    "    \n",
    "    NBC = NaiveBayesClassifier(sample_dim)\n",
    "    NBC.train(training_samples, training_labels)\n",
    "    pred = NBC.test(testing_samples, testing_labels)\n",
    "    \n",
    "    test_num = len(testing_labels)\n",
    "    correct_num = 0\n",
    "    for i in range(test_num):\n",
    "        if pred[i] == testing_labels[i]:\n",
    "            correct_num += 1\n",
    "\n",
    "    return [test_num, correct_num, correct_num / test_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(samples, labels, k=5):\n",
    "    \n",
    "    batch_size = int(samples.shape[0] / k)\n",
    "    correct_classification = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, k):\n",
    "        k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "        k_train_labels = np.hstack([labels[0 : i * batch_size], labels[(i + 1) * batch_size:]])\n",
    "\n",
    "        k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "        k_val_labels = labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "        res = NBClassifier(k_train_samples, k_train_labels, k_val_samples, k_val_labels)\n",
    "        \n",
    "        correct_classification += res[1]\n",
    "        total += res[0]\n",
    "        print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "        \n",
    "    return correct_classification / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC of 0th validation : 0.967\n",
      "ACC of 1th validation : 0.900\n",
      "ACC of 2th validation : 1.000\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 0.833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_validation(samples, labels, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMclassifier(kernel, training_samples, training_labels, testing_samples, testing_labels):\n",
    "    clf = svm.SVC(kernel=kernel, C=0.1)\n",
    "    clf.fit(training_samples, training_labels)\n",
    "    pred = clf.predict(testing_samples)\n",
    "    \n",
    "    test_num = len(testing_labels)\n",
    "    correct_num = 0\n",
    "    for i in range(test_num):\n",
    "        if pred[i] == testing_labels[i]:\n",
    "            correct_num += 1\n",
    "            \n",
    "    return [test_num, correct_num, correct_num / test_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_validation(samples, labels, k=5, kernel='linear'):\n",
    "    \n",
    "    batch_size = int(samples.shape[0] / k)\n",
    "    correct_classification = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(0, k):\n",
    "        k_train_samples = np.vstack([samples[0 : i * batch_size], samples[(i + 1) * batch_size :]])\n",
    "        k_train_labels = np.hstack([labels[0 : i * batch_size], labels[(i + 1) * batch_size:]])\n",
    "\n",
    "        k_val_samples = samples[i * batch_size : (i + 1) * batch_size]\n",
    "        k_val_labels = labels[i * batch_size : (i + 1) * batch_size]\n",
    "\n",
    "        res = SVMclassifier(kernel, k_train_samples, k_train_labels, k_val_samples, k_val_labels)\n",
    "        \n",
    "        correct_classification += res[1]\n",
    "        total += res[0]\n",
    "        print('ACC of %dth validation : %.3f' % (i, res[2]))\n",
    "        \n",
    "    print('total acc: %.3f' % (correct_classification / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel: linear\n",
      "ACC of 0th validation : 1.000\n",
      "ACC of 1th validation : 0.900\n",
      "ACC of 2th validation : 1.000\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 0.967\n",
      "total acc: 0.973\n",
      "kernel: rbf\n",
      "ACC of 0th validation : 0.967\n",
      "ACC of 1th validation : 0.900\n",
      "ACC of 2th validation : 1.000\n",
      "ACC of 3th validation : 1.000\n",
      "ACC of 4th validation : 0.800\n",
      "total acc: 0.933\n",
      "kernel: poly\n",
      "ACC of 0th validation : 1.000\n",
      "ACC of 1th validation : 0.933\n",
      "ACC of 2th validation : 1.000\n",
      "ACC of 3th validation : 0.967\n",
      "ACC of 4th validation : 0.933\n",
      "total acc: 0.967\n",
      "kernel: sigmoid\n",
      "ACC of 0th validation : 0.233\n",
      "ACC of 1th validation : 0.133\n",
      "ACC of 2th validation : 0.133\n",
      "ACC of 3th validation : 0.300\n",
      "ACC of 4th validation : 0.200\n",
      "total acc: 0.200\n"
     ]
    }
   ],
   "source": [
    "for kernel in ['linear', 'rbf', 'poly', 'sigmoid']:\n",
    "    print('kernel: %s' % (kernel))\n",
    "    Cross_validation(samples, labels, k=5, kernel=kernel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
